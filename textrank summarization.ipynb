{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"data/purchase.pickle\", 'rb') as p:\n",
    "    purchase = pickle.load(p)\n",
    "\n",
    "# 아이템 매칭 여부에 관계없이 리뷰 합치기\n",
    "df = purchase.groupby('리뷰자')['본문'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이스케이프 시퀀스 삭제 : \\n 제외\n",
    "df['본문'] = df['본문'].replace('\\xa0', ' ', regex=True)\n",
    "#특수문자 변경 : !, ^, _을 .으로\n",
    "df['본문'] = df['본문'].replace(r'\\!', '.', regex=True).replace(r'\\^', '.', regex=True).replace(r'\\_', '.', regex=True)\n",
    "# .을 \\n으로 변경\n",
    "df['본문'] = df['본문'].replace(r'\\.', '\\n', regex=True)\n",
    "# ㅋㅋㅋ ㅎㅎㅎ 등은 \\n으로\n",
    "df['본문'] = df['본문'].replace(r'[ㄱ-ㅎ]', '\\n', regex=True)\n",
    "# 기타 특수문자 제거\n",
    "df['본문'] = df['본문'].replace(r'[^0-9가-힣a-zA-Z\\s\\n]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"textrank_all item.csv\", encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### textrank 알고리즘\n",
    "- gensim은 한국어를 지원해주지 않음 -> 길이가 짧을 경우 요약 안 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textrankr\n",
      "  Downloading textrankr-1.1-py3-none-any.whl (7.2 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\a\\anaconda3\\envs\\test\\lib\\site-packages (from textrankr) (65.6.3)\n",
      "Collecting networkx\n",
      "  Downloading networkx-2.6.3-py3-none-any.whl (1.9 MB)\n",
      "     ---------------------------------------- 1.9/1.9 MB 30.4 MB/s eta 0:00:00\n",
      "Installing collected packages: networkx, textrankr\n",
      "Successfully installed networkx-2.6.3 textrankr-1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install textrankr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lexrankr\n",
      "  Downloading lexrankr-1.0-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\a\\anaconda3\\envs\\test\\lib\\site-packages (from lexrankr) (1.21.6)\n",
      "Requirement already satisfied: networkx in c:\\users\\a\\anaconda3\\envs\\test\\lib\\site-packages (from lexrankr) (2.6.3)\n",
      "Requirement already satisfied: gensim in c:\\users\\a\\anaconda3\\envs\\test\\lib\\site-packages (from lexrankr) (3.8.3)\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.post5.tar.gz (3.7 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: setuptools in c:\\users\\a\\anaconda3\\envs\\test\\lib\\site-packages (from lexrankr) (65.6.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\a\\anaconda3\\envs\\test\\lib\\site-packages (from lexrankr) (1.7.3)\n",
      "Requirement already satisfied: Cython==0.29.14 in c:\\users\\a\\anaconda3\\envs\\test\\lib\\site-packages (from gensim->lexrankr) (0.29.14)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\users\\a\\anaconda3\\envs\\test\\lib\\site-packages (from gensim->lexrankr) (1.16.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\a\\anaconda3\\envs\\test\\lib\\site-packages (from gensim->lexrankr) (6.3.0)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py): started\n",
      "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn: filename=sklearn-0.0.post5-py3-none-any.whl size=2970 sha256=10215e2257e39beec1f2bccdd2f5873af093c5c2e446d24629fa377386766240\n",
      "  Stored in directory: c:\\users\\a\\appdata\\local\\pip\\cache\\wheels\\b2\\af\\1b\\ac28f3fb36a8428e3089acdd913e9ee1808e781e3ff6ce2929\n",
      "Successfully built sklearn\n",
      "Installing collected packages: sklearn, lexrankr\n",
      "Successfully installed lexrankr-1.0 sklearn-0.0.post5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install lexrankr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textrankr import TextRank\n",
    "from lexrankr import LexRank\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"textrank_all item.csv\")\n",
    "\n",
    "# 결측값은 제외하고 요약\n",
    "df1 = df1.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -어요, -네요, -습니다, -아요 뒤에 \\n 삽입\n",
    "for i,j in enumerate(df1['본문']):\n",
    "    string = ['어요', '네요', '습니다', '아요']\n",
    "    text = j\n",
    "    for k in string:\n",
    "        idx = text.find(k)\n",
    "        if idx != -1:\n",
    "            text = text[:idx+len(k)] + '\\n' + text[idx+len(k):]\n",
    "        else:\n",
    "            text = text\n",
    "    df1.loc[i, '본문'] = text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### textrankr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTokenizer: #리스트 형식으로 저장하기 위한 클래스 선언\n",
    "    def __call__(self, text:str) -> List[str]:\n",
    "        tokens: List[str] = text.split()\n",
    "        return tokens\n",
    "    \n",
    "# 리스트 형식으로 저장하는 공간에 데이터들을 요약한다\n",
    "mytokenizer: MyTokenizer = MyTokenizer()\n",
    "textrank : TextRank = TextRank(mytokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['textrank1'] = np.nan\n",
    "\n",
    "for i,j in enumerate(df1['본문']):\n",
    "    summarized: str = textrank.summarize(j)\n",
    "    df1.loc[i, 'textrank1'] = summarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "리뷰자          0\n",
       "본문           0\n",
       "textrank1    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isna().sum() #전부 적용됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188, 3)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[df1['본문'] == df1['textrank1']].shape #요약 전후가 동일한 경우 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on TextRank in module textrankr.textrank object:\n",
      "\n",
      "class TextRank(builtins.object)\n",
      " |  TextRank(tokenizer: Callable[[str], List[str]], tolerance: float = 0.05) -> None\n",
      " |  \n",
      " |  Args:\n",
      " |      tokenizer: a function or a functor of Callable[[str], List[str]] type.\n",
      " |      tolerance: a threshold for omitting edge weights.\n",
      " |  \n",
      " |  Example:\n",
      " |      ```\n",
      " |      tokenizer: YourTokenizer = YourTokenizer()\n",
      " |      textrank: TextRank = TextRank(tokenzier, tolerance=0.05)\n",
      " |      summaries: str = textrank.summarize(your_text_here, num_sentences=True, verbose=True)\n",
      " |      print(summaries)\n",
      " |      ```\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, tokenizer: Callable[[str], List[str]], tolerance: float = 0.05) -> None\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  summarize(self, text: str, num_sentences: int = 3, verbose: bool = True) -> Union[str, List[str]]\n",
      " |      Summarizes the given text, using TextRank algorithm.\n",
      " |      \n",
      " |      Args:\n",
      " |          text: a raw text to be summarized.\n",
      " |          num_sentences: the number of sentences in a summarization result.\n",
      " |          verbose: if True, it will return a summarized raw text. It will return a summarized list of sentences otherwise.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(textrank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method summarize in module textrankr.textrank:\n",
      "\n",
      "summarize(text: str, num_sentences: int = 3, verbose: bool = True) -> Union[str, List[str]] method of textrankr.textrank.TextRank instance\n",
      "    Summarizes the given text, using TextRank algorithm.\n",
      "    \n",
      "    Args:\n",
      "        text: a raw text to be summarized.\n",
      "        num_sentences: the number of sentences in a summarization result.\n",
      "        verbose: if True, it will return a summarized raw text. It will return a summarized list of sentences otherwise.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(textrank.summarize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['textrank2'] = np.nan\n",
    "\n",
    "for i,j in enumerate(df1['본문']):\n",
    "    summarized: str = textrank.summarize(j, num_sentences=2) # 2줄 요약\n",
    "    df1.loc[i, 'textrank2'] = summarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "리뷰자          0\n",
       "본문           0\n",
       "textrank1    0\n",
       "textrank2    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isna().sum() #전부 적용됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173, 4)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[df1['본문'] == df1['textrank2']].shape #요약 전후가 동일한 경우 확인"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lexrankr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTokenizer: #리스트 형식으로 저장하기 위한 클래스 선언\n",
    "    def __call__(self, text:str) -> List[str]:\n",
    "        tokens: List[str] = text.split()\n",
    "        return tokens\n",
    "    \n",
    "# 리스트 형식으로 저장하는 공간에 데이터들을 요약한다\n",
    "mytokenizer: MyTokenizer = MyTokenizer()\n",
    "lexrank : LexRank = LexRank(mytokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['lexrank1'] = np.nan\n",
    "\n",
    "for i,j in enumerate(df1['본문']):\n",
    "    try:\n",
    "        lexrank.summarize(j)\n",
    "        summaries: List[str] = lexrank.probe()\n",
    "        df1.loc[i, 'lexrank1'] = ' '.join(summaries)\n",
    "    except ValueError:\n",
    "        text = j.replace(\"\\n\", \" \")\n",
    "        lexrank.summarize(text)\n",
    "        summaries: List[str] = lexrank.probe()\n",
    "        df1.loc[i, 'lexrank1'] = ' '.join(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "리뷰자          0\n",
       "본문           0\n",
       "textrank1    0\n",
       "textrank2    0\n",
       "lexrank1     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123, 5)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[df1['본문'] == df1['lexrank1']].shape #요약 전후가 동일한 경우 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on LexRank in module lexrankr.lexrankr object:\n",
      "\n",
      "class LexRank(builtins.object)\n",
      " |  LexRank(tokenizer: Callable[[str], List[str]], similarity_method: str = 'tfidf_cosine', similarity_decay_window: int = 20, similarity_decay_alpha: float = 0.25, similarity_matrix_diagonal_smoothing: bool = False, clustering_method: Union[str, NoneType] = 'birch', birch_threshold: float = 0.75, birch_n_clusters: Union[int, NoneType] = None, dbscan_eps: float = 1.0, min_cluster_size: int = 1, prune_duplicates: bool = True, pruning_threshold: float = 0.85) -> None\n",
      " |  \n",
      " |  Multi-document summarization. A key idea is to decay similarity values with sentence distance, then apply clustering.\n",
      " |  \n",
      " |  Args:\n",
      " |      tokenizer: A text tokenizer.\n",
      " |      similarity_method: One of 'tfidf_cosine', 'jaccard_index', 'normalized_cooccurrence'.\n",
      " |      similarity_decay_window: Any two sentences with further distance than this value will have 0 similarity.\n",
      " |      similarity_decay_alpha: An exponent for a sentence distance.\n",
      " |      similarity_matrix_diagonal_smoothing: If True, diagonal elements will have maximum value among each row except the respective diagonal value, which is 1.\n",
      " |      clustering_method: One of 'birch', 'dbscan', 'affinity_propagation', or None.\n",
      " |      birch_threshold: A threshold value for BIRCH, if selected.\n",
      " |      birch_n_clusters: The number of clusters for BIRCH, if selected.\n",
      " |      dbscan_eps: A threshold value for DBSCAN, if selected.\n",
      " |      min_cluster_size: Minimum number of sentences for each cluster.\n",
      " |      prune_duplicates: Prune duplicate sentences on the summarization result, if any.\n",
      " |      pruning_threshold: A threshold value for duplicate recognition (uses similarity values).\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, tokenizer: Callable[[str], List[str]], similarity_method: str = 'tfidf_cosine', similarity_decay_window: int = 20, similarity_decay_alpha: float = 0.25, similarity_matrix_diagonal_smoothing: bool = False, clustering_method: Union[str, NoneType] = 'birch', birch_threshold: float = 0.75, birch_n_clusters: Union[int, NoneType] = None, dbscan_eps: float = 1.0, min_cluster_size: int = 1, prune_duplicates: bool = True, pruning_threshold: float = 0.85) -> None\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  probe(self, k: Union[int, float] = 0) -> List[str]\n",
      " |  \n",
      " |  summarize(self, text: str, no_below: int = 3, no_above: float = 0.8, max_size: int = 20000) -> None\n",
      " |      Args:\n",
      " |          text: A text to be summarized.\n",
      " |          no_below: See `corpus.SentenceCorpus`.\n",
      " |          no_above: See `corpus.SentenceCorpus`.\n",
      " |          max_size: See `corpus.SentenceCorpus`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(lexrank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method probe in module lexrankr.lexrankr:\n",
      "\n",
      "probe(k: Union[int, float] = 0) -> List[str] method of lexrankr.lexrankr.LexRank instance\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(lexrank.probe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['lexrank2'] = np.nan\n",
    "\n",
    "for i,j in enumerate(df1['본문']):\n",
    "    try:\n",
    "        lexrank.summarize(j)\n",
    "        summaries: List[str] = lexrank.probe(k=0.4) #ratio 0.4\n",
    "        df1.loc[i, 'lexrank2'] = ' '.join(summaries)\n",
    "    except ValueError:\n",
    "        text = j.replace(\"\\n\", \" \")\n",
    "        lexrank.summarize(text)\n",
    "        summaries: List[str] = lexrank.probe(k=0.4)\n",
    "        df1.loc[i, 'lexrank2'] = ' '.join(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "리뷰자          0\n",
       "본문           0\n",
       "textrank1    0\n",
       "textrank2    0\n",
       "lexrank1     0\n",
       "lexrank2     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123, 6)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[df1['본문'] == df1['lexrank2']].shape #요약 전후가 동일한 경우 확인"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 후처리\n",
    "- \\n 및 특수문자 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 숫자, 한글, 영어, 공백만 남기기\n",
    "df1['본문'] = df1['본문'].replace(r'[^0-9가-힣a-zA-Z\\s]', '', regex=True)\n",
    "df1['textrank1'] = df1['textrank1'].replace(r'[^0-9가-힣a-zA-Z\\s]', '', regex=True)\n",
    "df1['textrank2'] = df1['textrank2'].replace(r'[^0-9가-힣a-zA-Z\\s]', '', regex=True)\n",
    "df1['lexrank1'] = df1['lexrank1'].replace(r'[^0-9가-힣a-zA-Z\\s]', '', regex=True)\n",
    "df1['lexrank2'] = df1['lexrank2'].replace(r'[^0-9가-힣a-zA-Z\\s]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\\n 삭제\n",
    "df1['본문'] = df1['본문'].replace('\\n','',regex=True)\n",
    "df1['textrank1'] = df1['textrank1'].replace('\\n','',regex=True)\n",
    "df1['textrank2'] = df1['textrank2'].replace('\\n','',regex=True)\n",
    "df1['lexrank1'] = df1['lexrank1'].replace('\\n','',regex=True)\n",
    "df1['lexrank2'] = df1['lexrank2'].replace('\\n','',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"data/textrank_lexrank.csv\", encoding='utf-8-sig', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
